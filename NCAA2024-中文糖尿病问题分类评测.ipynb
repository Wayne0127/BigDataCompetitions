{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8af783b2",
   "metadata": {},
   "source": [
    "# NCAA2024-中文糖尿病问题分类评测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24768b58",
   "metadata": {},
   "source": [
    "## 赛题背景"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0208d080",
   "metadata": {},
   "source": [
    "赛题链接：https://tianchi.aliyun.com/competition/entrance/532176  \n ",
    "中文糖尿病问题分类评测任务的目标是自动对患者提出的涉及糖尿病的问题进行分类。随着糖尿病成为全球重要的公共卫生挑战之一，互联网的迅速发展使得二型糖尿病患者和高危人群对专业信息的需求越来越迫切。因此，糖尿病自动问答服务在日常健康服务中的作用变得越来越重要。此任务的数据集包含了中文糖尿病问题分为6类。参与者需要对测试集中的糖尿病问题进行分类预测，并填补测试数据集中类别标签数据的空缺。评估过程将重点分析填充数据的误差，并给出预测性能得分。此外，本次任务也是NCAA 2024的评测任务之一，旨在提升搜索结果的准确性，推动糖尿病自动问答服务的发展。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e32c03",
   "metadata": {},
   "source": [
    "## 赛题任务"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd45f1b",
   "metadata": {},
   "source": [
    "NCAA 2024数据集基于NCAA 2023数据集进行补充增强。评测数据集包含的中文糖尿病问题一共分为6类，  \n",
    "包括诊断、治疗、常识、健康生活方式、流行病学、其他。  \n",
    "数据以 9：2：2 的比例划分为训练集、验证集和测试集。总计13000条数据。数据集都是以 .txt 格式存储。训练集、验证集和测试集包含question和label，分类数据集包含class和label。参赛者需要预测测试集中糖尿病问题对应的分类，预测完成后需将测试数据集空缺的类别标签数据进行填充。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0eea146",
   "metadata": {},
   "source": [
    "## 评分标准"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7377d689",
   "metadata": {},
   "source": [
    "该任务使用准确率（Acc，Accuracy）作为整体排名标准，公式如下\n",
    "$$\n",
    " \\text{准确率（Accuracy）} = \\frac{\\text{预测正确样本数}}{\\text{总样本数} } \n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7611a3",
   "metadata": {},
   "source": [
    "# 导入相关包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "ca275d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jieba,re\n",
    "from gensim import models, similarities\n",
    "import gensim.corpora as corpora\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoModel, AutoTokenizer,AutoConfig\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import word2vec\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import BertTokenizerFast\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.optim import AdamW,Adam\n",
    "from transformers import  get_linear_schedule_with_warmup,get_cosine_schedule_with_warmup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186a70ec",
   "metadata": {},
   "source": [
    "# 读取源数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "2c004698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取训练集\n",
    "train_df=pd.read_csv('train.txt', sep='\\t', header=None)\n",
    "valid_df=pd.read_csv('dev.txt', sep='\\t', header=None)\n",
    "test_df=pd.read_csv(\"test.txt\", sep='\\t', header=None)\n",
    "train_df.columns = ['text', 'label'] \n",
    "valid_df.columns = ['text', 'label'] \n",
    "test_df.columns =['text'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "59ebaa2f-8f6e-4b72-bd60-84efbb3d0c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "bcc44eac-747b-4624-8ea3-c0c6160916e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>空腹血糖78，是否属于糖尿病范围?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>减肥后是否能改善糖尿病状况?</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>患有糖尿病的母亲而父亲没有，是否会遗传给下一代?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>糖尿病是否会引起眼睛水肿?</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>妊娠期糖尿病的注意事项是什么?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       text  label\n",
       "0         空腹血糖78，是否属于糖尿病范围?      0\n",
       "1            减肥后是否能改善糖尿病状况?      3\n",
       "2  患有糖尿病的母亲而父亲没有，是否会遗传给下一代?      2\n",
       "3             糖尿病是否会引起眼睛水肿?      4\n",
       "4           妊娠期糖尿病的注意事项是什么?      2"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c9d097-59fc-43bd-926f-83d0d3cdeede",
   "metadata": {},
   "source": [
    "# CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "ac85756d-14c4-4cb5-a265-5d786ad3dad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd02ad6-058c-466d-8674-d2a6dbdf2e16",
   "metadata": {},
   "source": [
    "### 固定种子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "58583ff3-9f9a-4b59-90b5-3d5b0a452800",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87de2739-8cf4-4c67-a449-473f56648df9",
   "metadata": {},
   "source": [
    "# 数据观察"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "ea9c4ec2-d4af-4ad0-9927-c31c21057092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    2000 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 15.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# 无空值\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9664413-2ff5-4adf-a425-42cb3bed3bc7",
   "metadata": {},
   "source": [
    "查看各样本比例 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "f3ff08cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "3    2723\n",
       "1    2292\n",
       "2    1707\n",
       "4     897\n",
       "0     747\n",
       "5     634\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.value_counts('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "058e5679-4f3b-45b6-8e15-34650259b4f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 空腹血糖5.8是否偏高?\n",
       "1          2型糖尿病患者空腹血糖正常范围是多少?\n",
       "2        1型糖尿病性周围神经病变会导致下肢疼痛吗?\n",
       "3       42岁患有两年糖尿病史的男性可以食用海参吗?\n",
       "4                 糖尿病患者可以饮用茶吗?\n",
       "                 ...          \n",
       "1995             经常吃糖是否会引起糖尿病?\n",
       "1996             空腹血糖高是糖尿病病征吗?\n",
       "1997           患了糖尿病很焦虑应该如何应对?\n",
       "1998               糖尿病和智商有关系吗?\n",
       "1999             糖尿病可以不注射胰岛素吗?\n",
       "Name: text, Length: 2000, dtype: object"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe23b36-0206-4a7f-9d85-eef00f4041f9",
   "metadata": {},
   "source": [
    "## 设置参数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150cb499-cb1f-48bd-85da-f11c6836d2b9",
   "metadata": {},
   "source": [
    "## 选择预训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "36919b3e-3262-498d-bdec-ed7cf2e967ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer =AutoTokenizer.from_pretrained(\"chinese-roberta-wwm/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef82841-485c-4c07-844f-3ac0a7fe9295",
   "metadata": {},
   "source": [
    "## 定义MyDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "cf152472-03e3-4b70-8eff-0d895249989d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):  \n",
    "    def __init__(self, data, tokenizer, mode='train', device='cpu'):  \n",
    "        \"\"\"  \n",
    "        初始化数据集。  \n",
    "        :param data: 包含评论和标签的DataFrame或其他类似数据结构。  \n",
    "        :param tokenizer: 用于文本编码的分词器。  \n",
    "        :param mode: 数据集模式，'train'、'test' 或其他。  \n",
    "        :param device: 数据应被发送到的设备，通常是'cpu'或'cuda'（如果可用）。  \n",
    "        \"\"\"  \n",
    "        self.data = data  \n",
    "        self.tokenizer = tokenizer  \n",
    "        self.mode = mode  \n",
    "        self.device = device  \n",
    "        # 检查CUDA是否可用，如果指定了'cuda'但不可用，则回退到'cpu'  \n",
    "        if self.device == 'cuda' and not torch.cuda.is_available():  \n",
    "            self.device = 'cpu'  \n",
    "  \n",
    "    def __len__(self):  \n",
    "        \"\"\"返回数据集的大小。\"\"\"  \n",
    "        return len(self.data)  \n",
    "      \n",
    "    def __getitem__(self, index):  \n",
    "        \"\"\"  \n",
    "        返回给定索引处的样本，并确保它在正确的设备上。  \n",
    "        :param index: 样本索引。  \n",
    "        \"\"\"  \n",
    "        # 获取并编码文本  \n",
    "        text = self.data.loc[index, 'text']  \n",
    "        encoded_text = self.tokenizer.encode_plus(  \n",
    "            text,   \n",
    "            truncation=True,  \n",
    "            padding='max_length',  \n",
    "            max_length=32,  \n",
    "            return_tensors='pt'  \n",
    "        )  \n",
    "          \n",
    "        input_ids = encoded_text['input_ids'].to(self.device).squeeze()  \n",
    "        attention_mask = encoded_text['attention_mask'].to(self.device).squeeze()  \n",
    "          \n",
    "        # 根据模式返回样本  \n",
    "        if self.mode == 'train':  \n",
    "            label = self.data.loc[index, 'label']  \n",
    "            label_tensor = torch.tensor(label, device=self.device)            \n",
    "            return {  \n",
    "                'input_ids': input_ids,  \n",
    "                'attention_mask': attention_mask,  \n",
    "                'label': label_tensor  \n",
    "            }  \n",
    "        else:   \n",
    "            return {  \n",
    "                'input_ids': input_ids,  \n",
    "                'attention_mask': attention_mask  \n",
    "            }  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a75c3b3-3756-4cef-b8d0-7eaf0790bbb8",
   "metadata": {},
   "source": [
    "## 划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "a34d4f2f-bb22-431c-92c4-6686673187cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_data): 9000\n",
      "len(valid_data): 2000\n",
      "len(test_data): 2000\n"
     ]
    }
   ],
   "source": [
    "train_data = train_df.reset_index(drop=True)\n",
    "valid_data = valid_df.reset_index(drop=True)\n",
    "test_data = test_df.copy()\n",
    "\n",
    "print(\"len(train_data):\",len(train_data))\n",
    "print(\"len(valid_data):\",len(valid_data))\n",
    "print(\"len(test_data):\",len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "116baa5c-46b5-4b2f-8c90-c30ba4bc99cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='E:/NLP综合实践/阶段一/O2O商铺食品安全相关评论发现/chinese-roberta-wwm/', vocab_size=21128, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "f1ab44c0-4859-49cf-973f-ff414cf08d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调用 MyDataset\n",
    "# 训练集\n",
    "train_dataset = MyDataset(train_data, tokenizer=tokenizer,mode='train',device=device)\n",
    "# 验证集\n",
    "valid_dataset = MyDataset(valid_data, tokenizer=tokenizer,mode='train',device=device)\n",
    "# 测试集\n",
    "test_dataset = MyDataset(test_data, tokenizer=tokenizer,mode='test',device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "04c4b036-0957-4423-95ac-7616fea62c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调用 dataloader\n",
    "# 批处理大小\n",
    "batch_size = 32\n",
    "train_dataloader = DataLoader(train_dataset,batch_size = batch_size, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset,batch_size = batch_size, shuffle=False)\n",
    "test_dataloader  = DataLoader(test_dataset,batch_size = batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "4bdf98b2-b2ab-4269-a681-59f2dde79c31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a871808623b64223b6ec638550a91e0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101,  123, 1798,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101,  123, 1798,  ...,    0,    0,    0],\n",
      "        [ 101,  122, 1798,  ...,    0,    0,    0],\n",
      "        [ 101, 2642, 3300,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([4, 3, 3, 2, 3, 5, 3, 1, 3, 3, 1, 2, 0, 4, 2, 2, 2, 0, 1, 2, 4, 3, 3, 3,\n",
      "        3, 2, 3, 1, 3, 4, 1, 3], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101, 8203, 2259,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 2642, 3300,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 6117, 5131,  ...,    0,    0,    0],\n",
      "        [ 101, 1529,  745,  ...,    0,    0,    0],\n",
      "        [ 101, 2642, 3300,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([0, 2, 3, 0, 3, 3, 1, 1, 5, 3, 0, 4, 2, 1, 2, 3, 0, 2, 2, 4, 3, 4, 4, 1,\n",
      "        2, 1, 4, 0, 5, 5, 0, 3], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101, 6117, 5131,  ...,    0,    0,    0],\n",
      "        [ 101,  886, 4500,  ...,    0,    0,    0],\n",
      "        [ 101, 2642, 3300,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 2642, 3300,  ...,    0,    0,    0],\n",
      "        [ 101, 2642, 3300,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([0, 1, 5, 0, 2, 2, 3, 1, 3, 2, 1, 4, 2, 1, 5, 3, 2, 0, 2, 1, 1, 0, 1, 2,\n",
      "        5, 1, 4, 1, 0, 4, 3, 1], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101, 2642, 3300,  ...,    0,    0,    0],\n",
      "        [ 101, 2642, 3300,  ...,    0,    0,    0],\n",
      "        [ 101,  711,  784,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 1969, 2027,  ...,    0,    0,    0],\n",
      "        [ 101, 5536, 2270,  ...,    0,    0,    0],\n",
      "        [ 101, 2861,  784,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([4, 2, 2, 2, 2, 4, 3, 3, 4, 0, 1, 1, 3, 1, 1, 1, 0, 1, 1, 0, 2, 5, 4, 1,\n",
      "        1, 3, 2, 0, 1, 3, 2, 0], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101,  753, 2259,  ...,    0,    0,    0],\n",
      "        [ 101, 5499, 5517,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([0, 1, 3, 3, 3, 2, 3, 1, 1, 2, 3, 4, 4, 1, 1, 2, 0, 4, 1, 2, 0, 2, 5, 2,\n",
      "        1, 4, 5, 4, 3, 2, 2, 3], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101, 7608, 4500,  ...,    0,    0,    0],\n",
      "        [ 101, 6117, 5131,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 7770, 6117,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([4, 0, 2, 3, 3, 1, 5, 5, 4, 2, 2, 3, 2, 3, 1, 1, 0, 1, 3, 3, 1, 0, 3, 1,\n",
      "        2, 3, 4, 1, 4, 0, 5, 2], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101,  753, 1798,  ...,    0,    0,    0],\n",
      "        [ 101, 1398, 3198,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([5, 3, 3, 3, 4, 3, 3, 2, 4, 2, 1, 1, 4, 3, 1, 4, 4, 3, 3, 3, 0, 1, 3, 2,\n",
      "        1, 1, 2, 3, 1, 2, 0, 2], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101,  671, 5663,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 7623, 1400,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([0, 2, 0, 0, 4, 1, 4, 1, 3, 0, 1, 1, 1, 1, 2, 3, 2, 1, 3, 4, 2, 3, 3, 3,\n",
      "        5, 1, 1, 4, 3, 1, 3, 3], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101, 1391, 2130,  ...,    0,    0,    0],\n",
      "        [ 101,  123, 1798,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 7649, 1400,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([0, 4, 1, 3, 3, 0, 1, 2, 4, 3, 0, 1, 5, 2, 2, 1, 0, 3, 5, 3, 2, 3, 1, 1,\n",
      "        2, 0, 1, 1, 3, 0, 4, 2], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101, 1419, 3300,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 2642, 3300,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 7270, 3309,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([3, 2, 2, 4, 2, 3, 3, 4, 2, 0, 1, 4, 3, 1, 1, 0, 1, 4, 2, 1, 3, 2, 2, 1,\n",
      "        2, 4, 3, 1, 1, 1, 2, 3], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101,  122, 1798,  ...,    0,    0,    0],\n",
      "        [ 101,  123, 1798,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 5283, 5122,  ...,    0,    0,    0],\n",
      "        [ 101, 7770, 6117,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([2, 0, 5, 3, 4, 5, 1, 2, 2, 3, 3, 3, 1, 1, 0, 4, 0, 3, 1, 3, 4, 3, 3, 3,\n",
      "        2, 2, 4, 3, 0, 0, 3, 3], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 5307, 2382,  ...,    0,    0,    0],\n",
      "        [ 101, 6822, 6121,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([3, 4, 4, 3, 4, 2, 3, 3, 2, 2, 2, 3, 3, 2, 1, 3, 5, 4, 5, 3, 3, 1, 3, 2,\n",
      "        3, 2, 3, 3, 3, 2, 5, 4], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 3780, 4545,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101,  123, 1798,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([4, 4, 5, 4, 0, 1, 3, 1, 1, 0, 3, 3, 2, 1, 1, 1, 4, 1, 0, 3, 2, 3, 3, 2,\n",
      "        3, 3, 2, 5, 4, 4, 2, 3], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101,  122, 1798,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 1068, 5688,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5612, 7608,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([2, 3, 4, 1, 2, 1, 1, 1, 1, 1, 4, 1, 5, 1, 1, 2, 2, 3, 5, 1, 2, 1, 3, 1,\n",
      "        1, 1, 1, 1, 3, 1, 4, 2], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101,  872, 1962,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101,  122, 1798,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 6117, 5131,  ...,    0,    0,    0],\n",
      "        [ 101, 5503, 5523,  ...,    0,    0,    0],\n",
      "        [ 101, 3424, 7987,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([1, 1, 4, 0, 1, 4, 1, 1, 3, 1, 2, 5, 2, 3, 4, 0, 1, 0, 0, 3, 2, 0, 1, 2,\n",
      "        4, 1, 3, 1, 4, 3, 2, 1], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101, 7770, 5131,  ...,    0,    0,    0],\n",
      "        [ 101, 5439, 2399,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 1296, 5283,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([3, 3, 1, 4, 2, 2, 4, 4, 1, 4, 2, 1, 0, 4, 2, 0, 0, 3, 3, 1, 2, 5, 1, 4,\n",
      "        2, 1, 2, 2, 2, 0, 2, 3], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101, 6818, 1288,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 1296, 1825,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101,  676, 3714,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 3193, 3309,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([2, 2, 1, 2, 1, 3, 5, 1, 1, 2, 1, 4, 3, 2, 4, 3, 1, 3, 3, 3, 0, 5, 2, 1,\n",
      "        1, 1, 1, 2, 2, 3, 3, 2], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101,  123, 1798,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 2642, 3300,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([1, 2, 3, 3, 1, 1, 3, 3, 1, 3, 3, 1, 3, 3, 1, 3, 0, 3, 4, 2, 1, 5, 0, 3,\n",
      "        4, 2, 4, 2, 1, 4, 3, 3], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101, 5536, 5593,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 7965, 2094,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 5439, 2399,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([2, 5, 2, 3, 1, 4, 4, 2, 3, 1, 1, 2, 2, 3, 1, 1, 4, 3, 2, 2, 1, 4, 3, 1,\n",
      "        1, 2, 3, 3, 2, 4, 3, 3], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101,  711,  784,  ...,    0,    0,    0],\n",
      "        [ 101, 7649, 1400,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 9101, 8207,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([2, 0, 1, 3, 2, 3, 0, 1, 2, 4, 3, 2, 3, 1, 2, 4, 1, 1, 0, 1, 3, 5, 1, 2,\n",
      "        3, 2, 1, 3, 1, 5, 2, 0], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101, 6117, 5131,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 6117, 5131,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101,  126, 2259,  ...,    0,    0,    0],\n",
      "        [ 101,  969, 2595,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([0, 1, 0, 3, 5, 2, 3, 3, 0, 2, 3, 3, 1, 3, 1, 1, 3, 4, 2, 3, 0, 3, 2, 3,\n",
      "        4, 2, 1, 1, 2, 1, 1, 1], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101, 7623, 1400,  ...,    0,    0,    0],\n",
      "        [ 101, 1061, 2259,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5687, 3996,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([0, 3, 3, 4, 2, 3, 3, 2, 1, 5, 0, 1, 1, 1, 1, 2, 2, 1, 4, 1, 2, 1, 1, 2,\n",
      "        3, 3, 3, 4, 1, 1, 4, 2], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101,  123, 1798,  ...,    0,    0,    0],\n",
      "        [ 101, 2642, 3300,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 2642, 3300,  ...,    0,    0,    0],\n",
      "        [ 101, 7608, 4500,  ...,    0,    0,    0],\n",
      "        [ 101, 2399, 6768,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([3, 3, 2, 3, 2, 1, 1, 3, 3, 2, 1, 5, 0, 1, 3, 2, 3, 2, 2, 2, 3, 1, 3, 2,\n",
      "        3, 3, 5, 2, 3, 1, 2, 2], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 2642, 3300,  ...,    0,    0,    0],\n",
      "        [ 101, 6117, 5131,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101,  123, 1798,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([3, 1, 0, 4, 1, 4, 3, 5, 1, 4, 2, 1, 2, 3, 3, 1, 1, 2, 3, 2, 0, 3, 1, 3,\n",
      "        2, 1, 4, 3, 1, 2, 5, 4], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101,  711,  784,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 1969, 2027,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([2, 3, 4, 3, 4, 4, 1, 1, 3, 0, 2, 2, 2, 1, 3, 1, 4, 3, 4, 4, 2, 4, 1, 5,\n",
      "        0, 2, 3, 3, 1, 3, 1, 3], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101,  123, 1798,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 7608, 4500,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 7608, 4500,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([1, 4, 3, 3, 0, 5, 1, 3, 1, 1, 2, 3, 1, 0, 2, 1, 2, 1, 3, 3, 1, 3, 4, 5,\n",
      "        2, 1, 2, 3, 2, 4, 2, 2], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101,  123, 1798,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([4, 3, 0, 0, 2, 0, 2, 0, 1, 1, 5, 2, 5, 5, 4, 2, 3, 1, 0, 1, 4, 2, 1, 1,\n",
      "        1, 1, 5, 0, 2, 3, 3, 1], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101,  711,  784,  ...,    0,    0,    0],\n",
      "        [ 101,  753, 1798,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101,  753, 1798,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101,  753, 1798,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([1, 2, 5, 4, 5, 1, 1, 0, 4, 0, 1, 1, 5, 2, 4, 0, 1, 5, 1, 3, 3, 3, 1, 5,\n",
      "        3, 1, 2, 3, 2, 2, 1, 2], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 3300, 5131,  ...,    0,    0,    0],\n",
      "        [ 101, 1908, 3175,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([2, 2, 1, 3, 1, 3, 3, 1, 2, 3, 3, 2, 1, 3, 2, 1, 3, 0, 0, 0, 1, 3, 1, 1,\n",
      "        0, 1, 2, 4, 1, 4, 4, 0], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101,  753, 1798,  ...,    0,    0,    0],\n",
      "        [ 101, 7474, 5549,  ...,    0,    0,    0],\n",
      "        [ 101, 2797, 7937,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101,  753, 4508,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([3, 2, 0, 1, 4, 1, 1, 2, 1, 2, 1, 1, 3, 3, 2, 0, 3, 3, 3, 2, 2, 2, 0, 3,\n",
      "        1, 0, 1, 0, 3, 2, 1, 3], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101, 6117, 5131,  ...,    0,    0,    0],\n",
      "        [ 101, 2642, 3300,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 6117, 5131,  ...,    0,    0,    0],\n",
      "        [ 101, 2642, 3300,  ...,    0,    0,    0],\n",
      "        [ 101, 3241,  677,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([3, 5, 1, 1, 3, 0, 2, 0, 3, 1, 3, 1, 4, 1, 4, 4, 2, 1, 0, 3, 3, 0, 5, 5,\n",
      "        0, 1, 1, 2, 0, 0, 2, 2], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101, 2642, 3300,  ...,    0,    0,    0],\n",
      "        [ 101, 6117, 5131,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 5273, 5763,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([2, 3, 1, 0, 1, 5, 2, 1, 3, 4, 1, 1, 1, 2, 4, 3, 3, 2, 4, 3, 1, 1, 0, 2,\n",
      "        1, 2, 3, 0, 1, 3, 2, 2], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101, 4706, 4906,  ...,    0,    0,    0],\n",
      "        [ 101, 1036, 4997,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 2769, 3221,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([4, 0, 2, 3, 3, 1, 3, 0, 3, 2, 3, 3, 1, 3, 3, 3, 3, 2, 3, 3, 5, 1, 3, 3,\n",
      "        2, 3, 0, 0, 1, 1, 1, 2], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101, 2769, 4638,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5318, 5307,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 2399, 6768,  ...,    0,    0,    0],\n",
      "        [ 101, 1391, 1298,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([2, 3, 2, 4, 4, 0, 2, 2, 3, 2, 1, 2, 2, 2, 2, 3, 1, 0, 2, 1, 2, 1, 0, 3,\n",
      "        0, 2, 1, 4, 3, 0, 1, 2], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101, 3193, 6629,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 3680, 1921,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([3, 3, 1, 2, 2, 4, 3, 1, 5, 3, 2, 1, 3, 3, 2, 2, 1, 3, 1, 3, 2, 2, 3, 3,\n",
      "        4, 3, 1, 2, 2, 3, 3, 4], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 2642, 3300,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 3221, 1415,  ...,    0,    0,    0],\n",
      "        [ 101, 3300, 5131,  ...,    0,    0,    0],\n",
      "        [ 101, 6117, 5131,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([1, 2, 2, 4, 3, 0, 3, 2, 0, 2, 3, 2, 1, 4, 2, 1, 3, 2, 0, 1, 3, 3, 1, 1,\n",
      "        1, 1, 2, 1, 2, 1, 4, 5], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 1963,  862,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([2, 1, 1, 0, 2, 0, 3, 3, 2, 0, 0, 3, 2, 2, 3, 1, 3, 2, 3, 4, 3, 4, 3, 2,\n",
      "        4, 3, 2, 0, 1, 2, 2, 2], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101, 5307, 2382,  ...,    0,    0,    0],\n",
      "        [ 101, 3300, 5131,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 2769, 1377,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([3, 2, 0, 3, 0, 3, 3, 0, 3, 1, 0, 1, 2, 5, 3, 3, 5, 5, 3, 5, 1, 3, 2, 3,\n",
      "        2, 3, 2, 4, 2, 3, 0, 3], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5536, 2270,  ...,    0,    0,    0],\n",
      "        [ 101, 1391,  784,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5543, 6382,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([2, 1, 3, 3, 0, 2, 4, 1, 4, 1, 2, 3, 2, 1, 1, 4, 2, 2, 3, 2, 2, 3, 4, 3,\n",
      "        5, 3, 0, 0, 3, 2, 2, 1], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101, 2523, 1331,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 3815, 2209,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([2, 2, 2, 3, 1, 1, 2, 1, 4, 3, 2, 1, 2, 4, 1, 0, 2, 3, 5, 1, 3, 4, 0, 4,\n",
      "        4, 3, 1, 2, 2, 1, 1, 3], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101, 3844, 7030,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5536, 2270,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 3378,  782,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 7270, 3309,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([0, 5, 2, 2, 3, 1, 3, 2, 4, 2, 3, 3, 2, 2, 1, 3, 1, 1, 4, 3, 5, 2, 2, 5,\n",
      "        0, 2, 4, 4, 3, 4, 4, 2], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 2642, 3300,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([3, 0, 4, 3, 0, 0, 3, 2, 3, 2, 2, 1, 2, 2, 3, 5, 3, 2, 2, 2, 3, 3, 3, 2,\n",
      "        0, 3, 3, 0, 3, 3, 1, 1], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 1957, 2595,  ...,    0,    0,    0],\n",
      "        [ 101, 5543, 1415,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5558, 2900,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([4, 2, 2, 4, 2, 5, 1, 1, 4, 3, 2, 2, 3, 5, 4, 2, 2, 3, 3, 3, 3, 1, 4, 2,\n",
      "        3, 3, 2, 5, 3, 1, 0, 1], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101, 7270, 3309,  ...,    0,    0,    0],\n",
      "        [ 101, 3193, 3309,  ...,    0,    0,    0],\n",
      "        [ 101, 2642, 5131,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101,  671, 1798,  ...,    0,    0,    0],\n",
      "        [ 101, 2770, 5131,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([1, 3, 5, 2, 4, 1, 1, 1, 0, 2, 5, 3, 0, 4, 0, 3, 3, 5, 1, 0, 3, 2, 2, 2,\n",
      "        5, 3, 3, 2, 2, 2, 3, 2], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 8203, 2259,  ...,    0,    0,    0],\n",
      "        [ 101, 1963, 3362,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([1, 4, 1, 0, 1, 4, 1, 0, 3, 2, 3, 3, 2, 3, 3, 2, 5, 4, 4, 2, 3, 2, 3, 4,\n",
      "        0, 2, 1, 1, 1, 1, 1, 4], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101, 8192, 2259,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 3300, 4617,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101,  784,  720,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([1, 5, 1, 1, 2, 2, 3, 5, 1, 2, 1, 3, 1, 1, 1, 1, 1, 3, 1, 4, 2, 1, 1, 4,\n",
      "        0, 1, 4, 1, 3, 3, 1, 2], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101, 2802, 4390,  ...,    0,    0,    0],\n",
      "        [ 101, 5536, 1147,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 3193, 7623,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([5, 2, 3, 3, 0, 1, 0, 0, 3, 2, 0, 5, 2, 2, 1, 3, 2, 1, 3, 1, 2, 3, 2, 1,\n",
      "        2, 2, 2, 5, 2, 2, 1, 3], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 3680, 1921,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 1795,  860,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([1, 4, 3, 3, 1, 4, 2, 2, 4, 3, 4, 2, 3, 4, 1, 0, 3, 3, 4, 2, 4, 1, 1, 3,\n",
      "        4, 5, 1, 4, 3, 1, 1, 5], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([1, 3, 1, 4, 3, 1, 3, 4, 5, 0, 0, 3, 4, 3, 0, 3, 4, 3, 3, 4, 3, 3, 4, 0,\n",
      "        1, 0, 1, 3, 4, 5, 1, 2], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101, 2793, 3425,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 2582, 3416,  ...,    0,    0,    0],\n",
      "        [ 101, 6117, 5131,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([4, 0, 3, 1, 3, 0, 1, 3, 1, 2, 2, 3, 4, 3, 1, 3, 2, 1, 0, 3, 0, 4, 3, 3,\n",
      "        0, 3, 2, 3, 2, 0, 0, 3], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101,  784,  720,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 1963,  862,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([3, 3, 2, 4, 4, 1, 0, 2, 4, 1, 0, 3, 3, 1, 4, 2, 1, 2, 3, 2, 0, 4, 3, 4,\n",
      "        0, 1, 2, 2, 0, 3, 1, 3], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101, 2714, 2595,  ...,    0,    0,    0],\n",
      "        [ 101, 6814,  754,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 7770, 6117,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([4, 2, 1, 2, 3, 4, 0, 1, 2, 2, 3, 4, 5, 0, 1, 3, 0, 1, 4, 1, 1, 1, 2, 3,\n",
      "        1, 1, 0, 3, 2, 2, 3, 0], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101, 1957, 2595,  ...,    0,    0,    0],\n",
      "        [ 101, 5439, 2399,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 2642, 3300,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([2, 1, 5, 4, 3, 2, 0, 3, 5, 2, 4, 3, 1, 2, 3, 3, 3, 0, 4, 3, 5, 2, 2, 1,\n",
      "        2, 5, 1, 1, 5, 3, 5, 1], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101, 1963,  862,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 2642, 3300,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 2342, 1920,  ...,    0,    0,    0],\n",
      "        [ 101, 2642, 3300,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([5, 2, 5, 1, 2, 3, 3, 4, 3, 2, 1, 5, 5, 3, 0, 0, 3, 2, 2, 3, 1, 0, 1, 5,\n",
      "        1, 1, 0, 4, 2, 2, 2, 0], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101, 2642, 3300,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 1391, 2341,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([1, 2, 3, 3, 2, 4, 3, 0, 3, 3, 1, 2, 1, 1, 0, 1, 1, 1, 0, 0, 5, 4, 0, 2,\n",
      "        2, 3, 0, 5, 1, 1, 1, 5], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101, 6117, 5131,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 7623, 1400,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([0, 5, 3, 1, 4, 2, 3, 3, 1, 1, 4, 4, 5, 2, 1, 0, 4, 2, 0, 5, 3, 5, 2, 2,\n",
      "        2, 3, 1, 3, 1, 0, 1, 3], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101, 6133, 7207,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 1391, 4242,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([1, 1, 2, 2, 3, 2, 3, 1, 0, 4, 1, 3, 1, 2, 3, 1, 1, 2, 1, 3, 3, 2, 1, 5,\n",
      "        3, 5, 3, 3, 2, 1, 2, 3], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 2228, 5131,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([2, 0, 4, 2, 1, 2, 1, 5, 2, 2, 0, 3, 0, 0, 2, 2, 4, 0, 2, 2, 1, 2, 2, 2,\n",
      "        0, 1, 0, 5, 4, 2, 2, 2], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 4958, 5592,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 2642, 3300,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([4, 1, 0, 2, 3, 3, 1, 1, 0, 1, 1, 1, 5, 3, 0, 5, 2, 2, 3, 4, 3, 4, 5, 3,\n",
      "        3, 4, 4, 3, 1, 1, 2, 2], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101, 4684, 5499,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 3969, 4562,  ...,    0,    0,    0],\n",
      "        [ 101, 5513, 5310,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([4, 5, 1, 3, 2, 1, 0, 3, 1, 4, 1, 2, 5, 4, 0, 2, 1, 4, 0, 1, 1, 1, 2, 2,\n",
      "        3, 5, 1, 0, 2, 2, 0, 2], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5513, 2207,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([4, 2, 0, 3, 2, 2, 1, 3, 5, 1, 1, 2, 1, 3, 2, 4, 5, 2, 5, 0, 0, 4, 4, 1,\n",
      "        1, 1, 1, 2, 5, 5, 2, 1], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 3473, 3522,  ...,    0,    0,    0],\n",
      "        [ 101, 1391, 5951,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0],\n",
      "        [ 101, 2048, 1036,  ...,    0,    0,    0],\n",
      "        [ 101, 5131, 2228,  ...,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'label': tensor([5, 3, 3, 2, 2, 2, 0, 5, 1, 1, 5, 4, 1, 3, 3, 2, 2, 3, 1, 5, 5, 5, 5, 5,\n",
      "        5, 0, 5, 0, 1, 5, 2, 5], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 101, 1196, 4164, 6817, 1220, 3221, 1415,  833, 6430, 1355, 5131, 2228,\n",
      "         4567,  136,  102,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [ 101, 5131, 2228, 4567, 2642, 5442, 5543,  679, 5543, 1916, 1346, 1217,\n",
      "         2787, 1912, 2861, 5298,  136,  102,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [ 101, 8267, 2259,  809,  677, 5131, 2228, 4567, 2642, 5442, 2582, 3416,\n",
      "         2612, 1908,  978, 2434,  136,  102,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [ 101, 5131, 2228, 4567, 3221, 1415,  833, 2471, 1355, 5564, 1355,  136,\n",
      "          102,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [ 101, 5131, 2228, 4567, 3221, 1415,  833, 2193, 5636, 7583, 1928, 7270,\n",
      "         1139, 4546, 4609,  136,  102,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [ 101, 2642, 3300, 5131, 2228, 4567, 4638, 6117, 5131, 6814, 7770, 1963,\n",
      "          862, 1905, 4415,  136,  102,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [ 101, 5131, 2228, 4567, 2642, 5442, 1909, 2108, 1963,  862, 6822, 6121,\n",
      "          978, 2434, 3189, 1045, 3861,  136,  102,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [ 101, 5131, 2228, 4567, 3780, 4545, 3126, 3362, 3297, 1962, 4638, 5536,\n",
      "         2270, 5162,  817, 3419, 3221, 1914, 2208,  136,  102,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [ 101, 5131, 2228, 4567, 2642, 5442, 1963,  862, 6822, 6121, 6844, 2428,\n",
      "         6817, 1220,  136,  102,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [ 101, 5131, 2228, 4567, 5558, 2419, 1355, 4178, 2582,  720, 6237, 1104,\n",
      "          136,  102,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [ 101, 5131, 2228, 4567, 2642, 5442, 3300, 5517, 7000, 1411, 1498, 1737,\n",
      "         7410, 2582,  720, 1215,  136,  102,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [ 101, 1762, 5790, 4289, 3780, 4545, 4638, 1398, 3198, 3221, 1415, 5543,\n",
      "         1916, 5131, 2228, 4567,  782, 6651, 3635, 7248, 4159,  136,  102,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [ 101, 5131, 2228, 4567, 2642, 5442,  860, 7676, 3221, 1415,  833, 3300,\n",
      "         1359, 1265,  136,  102,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [ 101, 5131, 2228, 4567, 2642, 5442, 1377,  809, 6822, 6121, 1525,  763,\n",
      "         3300, 3709, 6817, 1220,  136,  102,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [ 101, 5131, 2228, 4567, 2642, 5442, 3221, 1415, 1377,  809, 6822, 6121,\n",
      "         5592, 6956, 2902, 3040,  136,  102,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [ 101, 5131, 2228, 4567, 6639, 5558, 2419, 5514, 5515, 2582,  720, 1905,\n",
      "         4415,  136,  102,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'label': tensor([2, 3, 1, 2, 2, 1, 5, 5, 3, 1, 1, 3, 2, 3, 3, 1], device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "for val_batch in tqdm(valid_dataloader):\n",
    "    print(val_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2af441-6b32-44ab-9669-1cdec518259c",
   "metadata": {},
   "source": [
    "## 模型定义"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775d80e4-7060-4b16-abff-b600790df407",
   "metadata": {},
   "source": [
    "## RoBerta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "b72838c1-d7fc-4ced-853e-c2d5021b9731",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyBERT(nn.Module):\n",
    "    def __init__(self, num_classes=6):\n",
    "        super(MyBERT, self).__init__()\n",
    "        # 加载 RoBERTa 预训练模型的配置\n",
    "        config = AutoConfig.from_pretrained(\"chinese-roberta-wwm/\")\n",
    "        # 加载 RoBERTa 预训练模型\n",
    "        self.bert = AutoModel.from_pretrained(\"chinese-roberta-wwm/\", config=config)\n",
    "\n",
    "        self.out = nn.Linear(config.hidden_size , num_classes)  \n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # 获取 RoBERTa 的输出\n",
    "        bert_out = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask)\n",
    "        # 获取 RoBERTa 的 Pooler 输出\n",
    "        pooler = bert_out['pooler_output']\n",
    "        # 通过分类层进行分类\n",
    "        out = self.out(pooler)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "21a487c9-4f02-495d-b6c7-75d6ca124166",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert.embeddings.word_embeddings.weight\n",
      "bert.embeddings.position_embeddings.weight\n",
      "bert.embeddings.token_type_embeddings.weight\n",
      "bert.embeddings.LayerNorm.weight\n",
      "bert.embeddings.LayerNorm.bias\n"
     ]
    }
   ],
   "source": [
    "# 实例化模型\n",
    "model = MyBERT().to(device)\n",
    "model_name='Roberta'\n",
    "\n",
    "state_dict = model.state_dict()\n",
    "for name, param in state_dict.items():\n",
    "    if 'embedding' in name:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "7878705e-b305-4d3e-abd8-495ca04200f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyBERT(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (attention_pooling): AttentionPooling(\n",
      "    (attention): Sequential(\n",
      "      (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (2): GELU(approximate='none')\n",
      "      (3): Linear(in_features=768, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (out): Linear(in_features=1536, out_features=6, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efdc7bb-0f01-4ddd-af72-c3ac7a5ec081",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "3c0cfc56-ef91-4a78-b020-e85600656e38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#定义损失函数，优化器\n",
    "num_epochs=20\n",
    "\n",
    "#交叉熵损失函数\n",
    "loss_fn=nn.CrossEntropyLoss()\n",
    "\n",
    "#优化器\n",
    "optimizer = Adam(model.parameters(), lr=5e-5)\n",
    "\n",
    "total_steps=num_epochs * len(train_dataloader)\n",
    "\n",
    "#学习率调度器\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, \n",
    "                                            num_training_steps=total_steps,\n",
    "                                            num_warmup_steps=total_steps*0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "9361b2cb-13ff-4933-b8fd-184a761391fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58373e254546448095c20d945b164084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "237c89115c8a401288ded6105db201be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/282 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch：1，平均训练损失：1.349181468486786\n",
      "epoch：1，平均训练损失：0.6432392776012421\n",
      "epoch：1，平均训练损失：0.5381557792425156\n",
      "epoch：1，平均训练损失：0.5547611939907074\n",
      "epoch：1，平均训练损失：0.5264460629224778\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "188185ac453b467baa0467c76fb155da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch：1，验证集准确率：0.7645000219345093，最高准确率：0.7645000219345093\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ada9132a8adb4eb382a15f547a4dd047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/282 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch：2，平均训练损失：0.4601567268371582\n",
      "epoch：2，平均训练损失：0.4581198078393936\n",
      "epoch：2，平均训练损失：0.41992669358849527\n",
      "epoch：2，平均训练损失：0.43913316175341605\n",
      "epoch：2，平均训练损失：0.38209172904491423\n",
      "epoch：2，平均训练损失：0.4109659829735756\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f5f73e642e24bc49bc8f3ed1231072c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch：2，验证集准确率：0.7675000429153442，最高准确率：0.7675000429153442\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a30d6f97796429b966a4a610f1e3043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/282 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch：3，平均训练损失：0.3283992297947407\n",
      "epoch：3，平均训练损失：0.26755280449986457\n",
      "epoch：3，平均训练损失：0.28388782918453215\n",
      "epoch：3，平均训练损失：0.2956021027266979\n",
      "epoch：3，平均训练损失：0.2917057816684246\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "760749b48fc74eaa9bc5f0f527b83b8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch：3，验证集准确率：0.7765000462532043，最高准确率：0.7765000462532043\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee57784568424f808a729093a0f55fa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/282 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch：4，平均训练损失：0.3065237145125866\n",
      "epoch：4，平均训练损失：0.16391824014484882\n",
      "epoch：4，平均训练损失：0.19317691370844842\n",
      "epoch：4，平均训练损失：0.16641070514917375\n",
      "epoch：4，平均训练损失：0.20199590243399143\n",
      "epoch：4，平均训练损失：0.16355374734848738\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc568f49cfbb438ab581b1586c186562",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch：4，验证集准确率：0.7690000534057617，最高准确率：0.7765000462532043\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eff8b86ad1644eda10604e45a9d3259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/282 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch：5，平均训练损失：0.14081998787820338\n",
      "epoch：5，平均训练损失：0.10697930347174406\n",
      "epoch：5，平均训练损失：0.09748037463054061\n",
      "epoch：5，平均训练损失：0.11912685234099626\n",
      "epoch：5，平均训练损失：0.10019121013581753\n",
      "epoch：5，平均训练损失：0.12270022213459014\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c550a1c830f540fc9b7acf54f9185144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch：5，验证集准确率：0.7700000405311584，最高准确率：0.7765000462532043\n",
      "CPU times: total: 3min 42s\n",
      "Wall time: 5min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "Best_acc = 0\n",
    "step = 0\n",
    "loss_sum = 0\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    model.train()  # 设置为训练模式\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        step += 1\n",
    "\n",
    "        # 正常训练\n",
    "        out = model(batch['input_ids'], batch['attention_mask'])\n",
    "        loss = loss_fn(out, batch['label'])\n",
    "        loss_sum += loss.item()\n",
    "        loss.backward()  # 正向传播\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if step % 50 == 0:\n",
    "            print(f\"epoch：{epoch + 1}，平均训练损失：{loss_sum / 50}\")\n",
    "            loss_sum = 0\n",
    "            \n",
    "    # 验证集上进行评估 \n",
    "    model.eval()  # 设置为评估模式\n",
    "    valid_loss_sum = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    preds = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():  # 禁用梯度计算\n",
    "        for val_batch in tqdm(valid_dataloader):\n",
    "            outputs = model(val_batch['input_ids'], val_batch['attention_mask'])\n",
    "            predicted_labels = torch.argmax(outputs, 1)\n",
    "            correct += (predicted_labels == val_batch['label']).sum()\n",
    "            total += val_batch['label'].size(0)\n",
    "            preds.extend(list(predicted_labels.cpu().numpy()))\n",
    "            labels.extend(list(val_batch['label'].cpu().numpy()))\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    valid_losses.append(accuracy)\n",
    "    # 检查是否是当前最佳准确率\n",
    "    if Best_acc < accuracy:\n",
    "        Best_acc = accuracy\n",
    "        torch.save(model.state_dict(), f'{model_name}/model_{Best_acc}.bin')\n",
    "    print(f\"epoch：{epoch + 1}，验证集准确率：{accuracy}，最高准确率：{Best_acc}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "5322b2ec-e4ad-4647-b43f-bcb6ad8126b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010486189275979996"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "c2a4ce25-fc68-4d3e-88b4-e0d3b262bf67",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取保存路径下的模型名称，并提取分数\n",
    "scores = ['.'.join(model_name.split('_')[-1].split('.')[:-1]) for model_name in os.listdir(f\"{model_name}/\")]\n",
    "# 获取最高分\n",
    "Best_F1 = max(scores)\n",
    "# 加载训练中保存的最高分模型\n",
    "model = MyBERT().to(device)\n",
    "model.load_state_dict(torch.load(f'{model_name}/model_{Best_F1}.bin', map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "1d526619-f6fa-4bc7-964d-a91ca7f4cfc5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ab135bc525a4794890e67f890a4237f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 开始模型推理\n",
    "model.eval()\n",
    "preds = [] \n",
    "with torch.no_grad():  # 禁用梯度计算\n",
    "    for val_batch in tqdm(test_dataloader):\n",
    "        outputs = model(val_batch['input_ids'], val_batch['attention_mask'])\n",
    "        predicted_labels = torch.argmax(outputs, 1)\n",
    "        preds.extend(list(predicted_labels.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "c8e3a232-3c72-4c23-b060-e997c8440c48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 创建结果 DataFrame 的副本，以避免 SettingWithCopyWarning\n",
    "test_df.columns = ['text']\n",
    "result = test_df.copy()\n",
    "result['label'] = preds\n",
    "result.to_csv('result.txt', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "bb56d4f9-c449-4d9f-9024-e76af78ca5ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>空腹血糖5.8是否偏高?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2型糖尿病患者空腹血糖正常范围是多少?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1型糖尿病性周围神经病变会导致下肢疼痛吗?</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42岁患有两年糖尿病史的男性可以食用海参吗?</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>糖尿病患者可以饮用茶吗?</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>经常吃糖是否会引起糖尿病?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>空腹血糖高是糖尿病病征吗?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>患了糖尿病很焦虑应该如何应对?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>糖尿病和智商有关系吗?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>糖尿病可以不注射胰岛素吗?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        text  label\n",
       "0               空腹血糖5.8是否偏高?      0\n",
       "1        2型糖尿病患者空腹血糖正常范围是多少?      0\n",
       "2      1型糖尿病性周围神经病变会导致下肢疼痛吗?      4\n",
       "3     42岁患有两年糖尿病史的男性可以食用海参吗?      3\n",
       "4               糖尿病患者可以饮用茶吗?      3\n",
       "...                      ...    ...\n",
       "1995           经常吃糖是否会引起糖尿病?      2\n",
       "1996           空腹血糖高是糖尿病病征吗?      0\n",
       "1997         患了糖尿病很焦虑应该如何应对?      1\n",
       "1998             糖尿病和智商有关系吗?      2\n",
       "1999           糖尿病可以不注射胰岛素吗?      1\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "25a59669-5520-4155-aa72-7928712ff6ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
